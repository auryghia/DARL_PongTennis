{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd4658d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cella per installare le librerie necessarie\n",
    "! pip install pandas\n",
    "! pip install gymnasium[atari]\n",
    "! pip install ale-py\n",
    "! pip install tensorflow\n",
    "! pip install opencv-python\n",
    "! pip install matplotlib\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a6618b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd \n",
    "%run Pong-v0_A2C.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a24878f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inizio test...\n",
      "Spazio di osservazione dell'ambiente di test wrappato: Box(0, 255, (210, 160, 3), uint8)\n",
      "GPU not available, testing on CPU.\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Modello caricato da: checkpoints_\\pong_a2c_ckpt_300000_steps.zip\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from stable_baselines3 import A2C\n",
    "import torch\n",
    "import gymnasium as gym\n",
    "from ale_py import ALEInterface\n",
    "import ale_py\n",
    "import sys\n",
    "from stable_baselines3.common.atari_wrappers import AtariWrapper\n",
    "\n",
    "import os\n",
    "\n",
    "gym.register_envs(ale_py)\n",
    "\n",
    "ale = ALEInterface()\n",
    "env = gym.make(\"ALE/Pong-v5\")\n",
    "\n",
    "def test_agent(model_path, env, num_episodes=10, render=True, use_gpu=True):\n",
    "    \"\"\"\n",
    "    Testa un agente addestrato.\n",
    "\n",
    "    :param model_path: Percorso del modello salvato (.zip).\n",
    "    :param env: L'ambiente di test (dovrebbe essere lo stesso tipo di ambiente usato per l'addestramento).\n",
    "    :param num_episodes: Numero di episodi per cui testare l'agente.\n",
    "    :param render: Se True, renderizza l'ambiente durante il test.\n",
    "    :param use_gpu: Se True e la GPU è disponibile, carica il modello sulla GPU.\n",
    "    \"\"\"\n",
    "    # Determina il device\n",
    "    if use_gpu and torch.cuda.is_available():\n",
    "        current_device = torch.device(\"cuda\")\n",
    "        print(\"Testing on GPU.\")\n",
    "    else:\n",
    "        if use_gpu and not torch.cuda.is_available():\n",
    "            print(\"GPU not available, testing on CPU.\")\n",
    "        else:\n",
    "            print(\"Testing on CPU.\")\n",
    "        current_device = torch.device(\"cpu\")\n",
    "\n",
    "    # Carica il modello addestrato\n",
    "    # Assicurati che l'ambiente passato a A2C.load() sia un'istanza dell'ambiente\n",
    "    # o None se l'ambiente è già wrappato e non vuoi che SB3 lo wrappi di nuovo.\n",
    "    # Per coerenza, è meglio passare l'ambiente.\n",
    "\n",
    "    wrap_env =   AtariWrapper(env) # Aggiungi altri parametri se usati in addestramento\n",
    "\n",
    "    try:\n",
    "        model = A2C.load(model_path, env=wrap_env, device=current_device)\n",
    "        print(f\"Modello caricato da: {model_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Errore durante il caricamento del modello: {e}\")\n",
    "        return\n",
    "\n",
    "    total_rewards = []\n",
    "    total_steps = []\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        obs, _ = wrap_env.reset()\n",
    "        done = False\n",
    "        episode_reward = 0\n",
    "        episode_steps = 0\n",
    "        max_steps = 1000  # Limita il numero massimo di passi per episodio\n",
    "        while not done and episode_steps < max_steps:\n",
    "            # Usa deterministic=True per ottenere l'azione più probabile (comportamento di exploitation)\n",
    "            action, _states = model.predict(obs, deterministic=True)\n",
    "            obs, reward, done, _, info = wrap_env.step(action)\n",
    "            episode_reward += reward\n",
    "            episode_steps += 1\n",
    "            time.sleep(0.01)  # Rallenta un po' per la visualizzazione\n",
    "            if render:\n",
    "                wrap_env.render()  # Usa il metodo render dell'ambiente wrappato\n",
    "\n",
    "        if episode_steps >= max_steps:\n",
    "            print(f\"Raggiunto il limite massimo di passi ({max_steps}) per l'episodio.\")\n",
    "\n",
    "        total_rewards.append(episode_reward)\n",
    "        total_steps.append(episode_steps)\n",
    "        print(f\"Episodio {episode + 1}: Ricompensa = {episode_reward}, Steps = {episode_steps}\")\n",
    "\n",
    "    env.close() # Chiudi l'ambiente dopo il test\n",
    "    avg_reward = np.mean(total_rewards)\n",
    "    std_reward = np.std(total_rewards)\n",
    "    avg_steps = np.mean(total_steps)\n",
    "    print(f\"\\n--- Risultati del Test ---\")\n",
    "    print(f\"Numero di episodi: {num_episodes}\")\n",
    "    print(f\"Ricompensa media: {avg_reward:.2f} +/- {std_reward:.2f}\")\n",
    "    print(f\"Durata media episodio (steps): {avg_steps:.2f}\")\n",
    "    print(f\"--------------------------\")\n",
    "    return avg_reward, std_reward\n",
    "\n",
    "# ... (resto del codice, inclusa la funzione collect_observations) ...\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Esempio di come potresti eseguire l'addestramento e poi il test\n",
    "    \n",
    "    # 1. Crea l'ambiente\n",
    "    # env_train = make_env()\n",
    "    # env_train = DummyVecEnv([lambda: env_train]) # SB3 si aspetta un VecEnv\n",
    "\n",
    "    # 2. Addestra l'agente (o salta se hai già un modello)\n",
    "    # print(\"Inizio addestramento...\")\n",
    "    # trained_model_instance = train_agent(env_train, total_timesteps=200000, checkpoint_interval=50000, use_gpu=True)\n",
    "    # path_to_trained_model = \"checkpoints/pong_a2c.zip_checkpoint_200000.zip\" # Assicurati che il percorso sia corretto\n",
    "    # env_train.close()\n",
    "    # print(\"Addestramento completato.\")\n",
    "\n",
    "    # 3. Testa l'agente\n",
    "    print(\"\\nInizio test...\")\n",
    "    model_path = \"checkpoints_\\pong_a2c_ckpt_300000_steps.zip\"\n",
    "                                                                        # Dovrebbe essere il percorso esatto del tuo file .zip\n",
    "                                                                        # ad esempio, se save_path era \"checkpoints/pong_a2c\"\n",
    "                                                                        # e checkpoint_interval era 100000,\n",
    "                                                                        # il file per 200000 timesteps potrebbe essere\n",
    "                                                                        # \"checkpoints/pong_a2c_checkpoint_200000.zip\"\n",
    "                                                                        # o \"checkpoints/pong_a2c.zip_checkpoint_200000.zip\"\n",
    "                                                                        # a seconda di come hai costruito il nome.\n",
    "                                                                        # Controlla la tua cartella checkpoints!\n",
    "\n",
    "\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"ERRORE: Il file del modello {model_path} non esiste. Controlla il percorso.\")\n",
    "\n",
    "    else:\n",
    "        # Non è necessario wrappare in DummyVecEnv per A2C.load se passi l'ambiente singolo\n",
    "        # Tuttavia, se A2C.load si aspetta un VecEnv, allora wrappalo:\n",
    "        # env_test = DummyVecEnv([lambda: env_test])\n",
    "\n",
    "        ale = ALEInterface()\n",
    "        env = gym.make(\"ALE/Pong-v5\", render_mode='human' if True else None)\n",
    "        print(f\"Spazio di osservazione dell'ambiente di test wrappato: {env.observation_space}\")\n",
    "        test_agent(model_path, env, num_episodes=5, render=True, use_gpu=True)\n",
    "        test_agent(model_path, env, num_episodes=20, render=True, use_gpu=True)\n",
    "        # env_test.close() # test_agent ora chiude l'ambiente\n",
    "\n",
    "        env.close() # Chiudi l'ambiente dopo il test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b237ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import gymnasium as gym # Usato da Pong-v0_A2C.py\n",
    "from ale_py import ALEInterface # Usato da Pong-v0_A2C.py\n",
    "import ale_py # Per la registrazione automatica degli ambienti ALE\n",
    "import numpy as np # Usato da Pong-v0_A2C.py\n",
    "import tensorflow as tf # Per verificare la GPU\n",
    "\n",
    "# --- Configurazione GPU per TensorFlow ---\n",
    "# Specifica quale GPU usare. \n",
    "# \"0\" per la prima GPU, \"1\" per la seconda, ecc.\n",
    "# Commenta la riga seguente se vuoi che TensorFlow scelga automaticamente \n",
    "# o usi tutte le GPU disponibili.\n",
    "# Se non hai GPU o la configurazione CUDA non è corretta, TensorFlow userà la CPU.\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" \n",
    "\n",
    "# (Opzionale) Abilita la crescita della memoria per evitare che TensorFlow allochi tutta la memoria GPU all'inizio\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"Configurata crescita della memoria per {len(gpus)} GPU fisiche.\")\n",
    "    except RuntimeError as e:\n",
    "        # La crescita della memoria deve essere impostata prima che le GPU siano inizializzate\n",
    "        print(f\"Errore durante l'impostazione della crescita della memoria: {e}\")\n",
    "else:\n",
    "    print(\"Nessuna GPU fisica trovata da TensorFlow. L'esecuzione avverrà su CPU.\")\n",
    "\n",
    "print(f\"TensorFlow utilizzerà i seguenti dispositivi fisici GPU: {tf.config.list_physical_devices('GPU')}\")\n",
    "print(f\"Versione di TensorFlow: {tf.__version__}\")\n",
    "\n",
    "# Non è più necessaria la funzione test_agent di stable-baselines3 qui,\n",
    "# né gli import di torch o stable_baselines3 A2C,\n",
    "# poiché Pong-v0_A2C.py ha la sua implementazione e logica di test.\n",
    "# --- Esecuzione dello script Pong-v0_A2C.py ---\n",
    "# Assicurati che Pong-v0_A2C.py sia nella stessa directory di questo notebook,\n",
    "# o che sia nel PYTHONPATH.\n",
    "\n",
    "# Il comando magico %run esegue lo script specificato.\n",
    "# Lo script Pong-v0_A2C.py dovrebbe contenere nel suo blocco\n",
    "# if __name__ == \"__main__\":\n",
    "# la logica per avviare l'addestramento (es. agent.run()) o il test.\n",
    "# Modifica Pong-v0_A2C.py per eseguire l'azione desiderata (addestramento o test).\n",
    "\n",
    "\n",
    "# --- Alternativa: Importare la classe e chiamare i metodi (più flessibile) ---\n",
    "# Questo approccio richiede che Pong-v0_A2C.py sia strutturato in modo da poter importare\n",
    "# la classe A2CAgent senza eseguire automaticamente l'addestramento all'importazione.\n",
    "# Ad esempio, il blocco if __name__ == \"__main__\": in Pong-v0_A2C.py\n",
    "# non dovrebbe chiamare agent.run() se lo script è importato come modulo.\n",
    "\n",
    "# Se vuoi questo livello di controllo, dovresti modificare Pong-v0_A2C.py.\n",
    "# Per ora, questa cella è solo un esempio e non verrà eseguita.\n",
    "\n",
    "# from Pong_v0_A2C import A2CAgent # Assumendo che il file sia importabile\n",
    "\n",
    "# print(\"Creazione ambiente per test con A2CAgent...\")\n",
    "# gym.register_envs(ale_py) # Assicurati che sia registrato\n",
    "# env_keras_test = gym.make(\"ALE/Pong-v5\", render_mode='human') # o None se non vuoi renderizzare\n",
    "\n",
    "# agent_keras = A2CAgent(env_keras_test)\n",
    "\n",
    "# Per addestrare:\n",
    "# print(\"Inizio addestramento con A2CAgent dal notebook...\")\n",
    "# agent_keras.run()\n",
    "# print(\"Addestramento completato.\")\n",
    "\n",
    "# Per testare un modello addestrato (assicurati che i percorsi siano corretti):\n",
    "# actor_model_file = \"Models/Pong-v0_A2C_NOME_MODELLO_Actor.h5\" # Sostituisci con il nome effettivo\n",
    "# critic_model_file = \"Models/Pong-v0_A2C_NOME_MODELLO_Critic.h5\" # Il salvataggio del critico è commentato in Pong-v0_A2C.py\n",
    "# print(f\"Inizio test con A2CAgent dal notebook, caricando: {actor_model_file}\")\n",
    "# agent_keras.test(actor_model_file, critic_model_file) # Il metodo test in Pong-v0_A2C.py potrebbe aver bisogno di aggiustamenti\n",
    "# print(\"Test completato.\")\n",
    "\n",
    "# env_keras_test.close()\n",
    "print(\"Cella di esempio per chiamata diretta (non eseguita). Modifica Pong-v0_A2C.py per usare questo approccio.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
